import streamlit as st
import google.generativeai as genai

# 1. CONFIGURACI√ìN VISUAL
st.set_page_config(
    page_title="Asesor CATEM",
    page_icon="‚öñÔ∏è",
    layout="centered",
    initial_sidebar_state="expanded"
)

# 2. ESTILOS (ROJO CATEM)
st.markdown("""
    <style>
    h1 { color: #B71C1C !important; text-align: center; font-weight: bold; }
    .stChatMessage { border-radius: 15px; border: 1px solid #eee; }
    </style>
""", unsafe_allow_html=True)

# 3. BARRA LATERAL
with st.sidebar:
    st.header("üß∞ Herramientas")
    if st.button("üóëÔ∏è Borrar Historial", type="primary"):
        st.session_state.messages = []
        st.rerun()
    st.divider()
    st.info("ü§ñ **Modelo:** Gemini 1.5 Flash")
    st.warning("‚ö†Ô∏è Demo educativa. No es abogac√≠a real.")

# 4. CONEXI√ìN (CORREGIDA)
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    
    # --- CAMBIO CLAVE: Usamos 'gemini-1.5-flash-latest' ---
    model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction="""
Eres el Asesor Digital CATEM.
ROL: IA experta en derecho laboral mexicano (LFT).
TONO: Emp√°tico, firme y profesional.
OBJETIVO: Orientar sobre despidos, salarios y prestaciones.
REGLAS:
- Aclara que NO eres abogado humano.
- Despido: Sugiere NO firmar renuncia y calcular finiquito.
- Usa negritas para resaltar derechos.
""")
except Exception as e:
    st.error(f"Error de conexi√≥n: {e}")

# 5. CHAT
st.title("‚öñÔ∏è Asesor Digital CATEM")
st.markdown("<h3 style='text-align: center; color: #555;'>Tu aliado en la defensa laboral</h3>", unsafe_allow_html=True)

if "messages" not in st.session_state:
    st.session_state.messages = []

# Bienvenida
if len(st.session_state.messages) == 0:
    st.chat_message("assistant").write("¬°Hola compa√±ero! üë∑ Soy tu Asesor Virtual. ¬øTe despidieron injustificadamente? Cu√©ntame.")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Escribe tu problema aqu√≠..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    with st.chat_message("assistant"):
        with st.spinner("Analizando..."):
            try:
                response = model.generate_content(prompt)
                st.markdown(response.text)
                st.session_state.messages.append({"role": "model", "content": response.text})
            except Exception as e:
                st.error(f"Error: {e}")
